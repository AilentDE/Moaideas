# About this repository
Here's some project I created for my job .  
Not all of project be showed but I tried best to push any code whitch is safely .  
If you want to see how did I collect informations from internet , hope it could be helpful to you :D


# Why Jupyter Notebook ? Why not pyhon ?
Well... I beleve everyone know that jupyter is a kind of IDE for Python , and there's a more popular IDE `VSCode` exist.  
Actually I use VSCode more with other projects like Flask or Scrapy , but `jupyer` is better in crawler project with cell system I beleved .  
It's print style is comfortable and I enjoy using it for my crawl job .  
But I coverted it to `.py` for docker run finally so It's fine to use any IDE for any project .


## What is these projects use for ?
Here is description about these projects , you can see here first then select any file whitch you interest to .  
* `KS` set
    * `火車幣_convert` record convert with backer and follower with session tool .
    * `火車幣_savedata` record every project backer numbers on [Our Kickstarter project](https://www.kickstarter.com/projects/moaideas/steel-n-steam-hexagonal-metal-coins-for-train-games) .
    * `金屬_幣轉換率紀錄` the old way to record convert rate with Selenium .
    It's the same with `火車幣_convert` .
    * `KS_老外金屬幣` record follower number before our project start .
    * `KS_projects_collection` collect all projects on [Kickstarter](https://www.kickstarter.com/) and record follower numbers everyday .  
    But I'd like to change the way of Scrapy .  
* `twitter2discord` check new tweet and notice in discord . Used with TWITTER-API and DISCORD-WEBHOOK . It's seems to IFTTT but more detail settings .
* `haruka_see` just interest in Vtuber's subscription growing rate , so I use Youtube API and see the subscription number everyday .
There are many webside for this job now , so if you are interest in it , you can search many webside about it .  
* `tender_list` collect every tender whitch our company care and report in our slack APP .